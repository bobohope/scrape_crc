{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "login_url = 'https://secure.indeed.com/account/login'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = {'User_Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listhandler(lst):\n",
    "    b=[]\n",
    "    for i in range(0,5):\n",
    "        try:\n",
    "            b.append(lst[i])\n",
    "        except:\n",
    "            b.append('')\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ingester(string):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    from datetime import datetime\n",
    "    import re\n",
    "    import time\n",
    "    from elasticsearch import Elasticsearch\n",
    "    es = Elasticsearch()\n",
    "    #start session s\n",
    "    s = requests.session()\n",
    "    #login with login and password\n",
    "    r = s.post(login_url,data = data)\n",
    "    #get resume page1 \n",
    "    rq= s.get(string)\n",
    "    url = []\n",
    "    soup = ''\n",
    "    all_content=[]\n",
    "    soup = BeautifulSoup(rq.text,'html.parser')\n",
    "    content = soup.find_all('a', class_= 'app_link')\n",
    "    #get urls in a page\n",
    "    for c in content:\n",
    "        full = 'https://www.indeed.com'+c.attrs['href']\n",
    "        url.append(full)\n",
    "    cnt = len(content)\n",
    "    track = 0\n",
    "    #open each url and look for contents\n",
    "    for j in range(0,cnt):\n",
    "        track += 1\n",
    "        r = s.get(url[j],headers=header)\n",
    "        soup = BeautifulSoup(r.text,'html.parser')\n",
    "        #Resume name\n",
    "        name = soup.find('h1').text\n",
    "        name = name.title()\n",
    "        print(name)\n",
    "        #experience \n",
    "        experience_list = []\n",
    "        company_list=[]\n",
    "        YOE_list = []\n",
    "        jobtitle_list=[]\n",
    "        location_c_list=[]\n",
    "        if len(experiences) > 5:\n",
    "            experiences = [experiences[0],experiences[1],experiences[2],experiences[3],experiences[4]]\n",
    "        for experience in experiences:\n",
    "            if experience.find('p',class_='work_title title') is None:\n",
    "                jobtitle = 'No Job Title'\n",
    "            else:\n",
    "                jobtitle = experience.find('p',class_='work_title title').text\n",
    "            if experience.find('div',class_='work_company') is None:\n",
    "                comp_lo = 'No Company'\n",
    "            else:\n",
    "                comp_lo = experience.find('div',class_='work_company').text.split(' - ')\n",
    "            if len(comp_lo) == 2:\n",
    "                company,location_c = experience.find('div',class_='work_company').text.split(' - ')\n",
    "            elif len(comp_lo) ==1 :\n",
    "                company = experience.find('div',class_='work_company').text\n",
    "                location_c = 'No Company Location'\n",
    "            else:\n",
    "                company = 'No Company'\n",
    "            if experience.find('p',class_='work_dates') is not None:\n",
    "                YOE = 0\n",
    "                period = experience.find('p',class_='work_dates').text.split(' to ')\n",
    "                #print (period)   # AA BB 1, AA PRESENT 2 A PRESENT 3 A BB 4 AA B 5\n",
    "                if len(period) == 2:\n",
    "                    if period[1] == 'Present':\n",
    "                        try:\n",
    "                            period[1] = datetime.today().strftime('%B %Y')\n",
    "                        except:\n",
    "                            period[1] = datetime.today().strftime('%b %Y')\n",
    "                    if len(period[0]) > 4 and len(period[1]) > 4:\n",
    "                        #type AA BB\n",
    "                        try:\n",
    "                            prd = (datetime.strptime(period[1],'%B %Y').date()-\\\n",
    "                            datetime.strptime(period[0],'%B %Y').date())\n",
    "                        except:\n",
    "                            prd = (datetime.strptime(period[1],'%b %Y').date()-\\\n",
    "                            datetime.strptime(period[0],'%b %Y').date())\n",
    "                    \n",
    "                        YOE = int(abs(round(prd.days/365,0)))\n",
    "                    elif len(period[0]) > 4 and len(period[1]) < 5:\n",
    "                        #type AA B\n",
    "                        YOE = int(period[1])-int(period[0].split()[1])\n",
    "                    elif len(period[0]) < 5 and len(period[1]) > 4:\n",
    "                        #type A BB\n",
    "                        YOE = int(period[1].split()[1])-int(period[0])\n",
    "                    elif len(period[0]) < 5 and len(period[1]) < 5:\n",
    "                        #type A B\n",
    "                        YOE = int(period[1])-int(period[0])\n",
    "                else:\n",
    "                    YOE = 1\n",
    "                if YOE < 1:\n",
    "                    YOE = 0\n",
    "            else:\n",
    "                YOE = None\n",
    "            jobdesc = experience.find('p',class_='work_description')\n",
    "            if jobdesc is None:\n",
    "                desc = 'No job description'\n",
    "            else:\n",
    "                desc = jobdesc.text\n",
    "            #print(jobtitle,'\\n',company,location_c,'\\n',desc,'\\n',YOE,'year')\n",
    "            company_list.append(company)\n",
    "            YOE_list.append(YOE)\n",
    "            experience_list.append(desc)\n",
    "            jobtitle_list.append(jobtitle)\n",
    "            location_c_list.append(location_c)\n",
    "        #break\n",
    "            #education education-section last\n",
    "        educations = soup.find_all('div',class_=re.compile(r'education-section( \\w)*'))\n",
    "        school_list=[]\n",
    "        YOEdu_list = []\n",
    "        degree_list=[]\n",
    "        location_list = []\n",
    "        if len(educations) > 5:\n",
    "            educations = [educations[0],educations[1],educations[2],educations[3],educations[4]]\n",
    "        for e in educations:\n",
    "            if e.find('p', class_ = 'edu_title') is None:\n",
    "                degree = 'No Education Information'\n",
    "            else:\n",
    "                degree = e.find('p', class_ = 'edu_title').text\n",
    "            if e.find('div', class_='edu_school') is None:\n",
    "                edu_school = 'No School Information'\n",
    "            else:\n",
    "                edu_school = e.find('div',class_='edu_school').text.split(' - ')[0]\n",
    "            if e.find('div',class_='inline-block') is None:\n",
    "                edu_location = 'No Education Location Info'\n",
    "            else:\n",
    "                edu_location = e.find('div',class_='inline-block').text\n",
    "            if e.find('p',class_='edu_dates') is not None:\n",
    "                YOEdu = 0\n",
    "                edu_period = e.find('p',class_='edu_dates').text.split(' to ')\n",
    "                #print (edu_period)   # AA BB 1, AA PRESENT 2 A PRESENT 3 A BB 4 AA B 5\n",
    "                if len(edu_period) == 2:\n",
    "                    if edu_period[1] == 'Present':\n",
    "                        try:\n",
    "                            edu_period[1] = datetime.today().strftime('%B %Y')\n",
    "                        except:\n",
    "                            edu_period[1] = datetime.today().strftime('%b %Y')\n",
    "                    if len(edu_period[0]) > 4 and len(edu_period[1]) > 4:\n",
    "                        #type AA BB\n",
    "                        try:\n",
    "                            edu_prd = (datetime.strptime(edu_period[1],'%B %Y').date()-\\\n",
    "                            datetime.strptime(edu_period[0],'%B %Y').date())\n",
    "                        except:\n",
    "                            edu_prd = (datetime.strptime(edu_period[1],'%b %Y').date()-\\\n",
    "                            datetime.strptime(period[0],'%b %Y').date())\n",
    "                    \n",
    "                        YOEdu = int(abs(round(edu_prd.days/365,0)))\n",
    "                    elif len(edu_period[0]) > 4 and len(edu_period[1]) < 5:\n",
    "                        #type AA B\n",
    "                        YOEdu = int(edu_period[1])-int(edu_period[0].split()[1])\n",
    "                    elif len(edu_period[0]) < 5 and len(edu_period[1]) > 4:\n",
    "                        #type A BB\n",
    "                        YOEdu = int(edu_period[1].split()[1])-int(edu_period[0])\n",
    "                    elif len(edu_period[0]) < 5 and len(edu_period[1]) < 5:\n",
    "                        #type A B\n",
    "                        YOEdu = int(edu_period[1])-int(edu_period[0])\n",
    "                else:\n",
    "                    YOEdu = 1\n",
    "                if YOEdu < 1:\n",
    "                    YOEdu = 0\n",
    "            else:\n",
    "                YOEdu = None\n",
    "            #print(degree,'\\n',edu_school,edu_location,'\\n',YOEdu,'year')\n",
    "            school_list.append(edu_school)\n",
    "            YOEdu_list.append(YOEdu)\n",
    "            degree_list.append(degree)\n",
    "            location_list.append(edu_location)\n",
    "        \n",
    "            #Skills\n",
    "        skill_set = soup.find_all('span',class_='skill-text')\n",
    "        skills=''\n",
    "        for sk in skill_set:\n",
    "            skills += (sk.text)\n",
    "        #print(skills)\n",
    "            #Certifications/Licenses\n",
    "    \n",
    "        cert = soup.find_all('div',class_=re.compile(r'certification-section( \\w)*'))\n",
    "        certs = ''\n",
    "        for c in cert:\n",
    "            certs += (c.text)\n",
    "        #prepare list\n",
    "        company_list = listhandler(company_list)\n",
    "        YOE_list = listhandler(YOE_list)\n",
    "        experience_list = listhandler(experience_list)\n",
    "        jobtitle_list = listhandler(jobtitle_list)\n",
    "        location_c_list = listhandler(location_c_list)\n",
    "        school_list = listhandler(school_list)\n",
    "        YOEdu_list = listhandler(YOEdu_list)\n",
    "        degree_list = listhandler(degree_list)\n",
    "        location_list = listhandler(location_list)\n",
    "        es.index(index='resume',\n",
    "                    doc_type='test-type',\n",
    "                    body={'id': track,\n",
    "                        'applicant':name,\n",
    "                         \"experience\": {\n",
    "                             \"company_1\":company_list[0],\n",
    "                             \"title_1\":jobtitle_list[0],\n",
    "                             \"years of experience_1\":YOE_list[0],\n",
    "                             \"location_1\":location_c_list[0],\n",
    "                             \"description_1\":experience_list[0],\n",
    "                             \"company_2\":company_list[1],\n",
    "                             \"title_2\":jobtitle_list[1],\n",
    "                             \"years of experience_2\":YOE_list[1],\n",
    "                             \"location_2\":location_c_list[1],\n",
    "                             \"description_2\":experience_list[1],\n",
    "                             \"company_3\":company_list[2],\n",
    "                             \"title_3\":jobtitle_list[2],\n",
    "                             \"years of experience_3\":YOE_list[2],\n",
    "                             \"location_3\":location_c_list[2],\n",
    "                             \"description_3\":experience_list[2],\n",
    "                             \"company_4\":company_list[3],\n",
    "                             \"title_1\":jobtitle_list[3],\n",
    "                             \"years of experience_4\":YOE_list[3],\n",
    "                             \"location_4\":location_c_list[3],\n",
    "                             \"description_4\":experience_list[3],\n",
    "                             \"company_5\":company_list[4],\n",
    "                             \"title_5\":jobtitle_list[4],\n",
    "                             \"years of experience_5\":YOE_list[4],\n",
    "                             \"location_5\":location_c_list[4],\n",
    "                             \"description_5\":experience_list[4]\n",
    "                        },\n",
    "                        \"education\":{\n",
    "                            \"school_1\":school_list[0],\n",
    "                            \"degree_1\":degree_list[0],\n",
    "                            \"location_1\":location_list[0],\n",
    "                            \"yearsOfeducation_1\":YOEdu_list[0],\n",
    "                            \"school_2\":school_list[1],\n",
    "                            \"degree_2\":degree_list[1],\n",
    "                            \"location_2\":location_list[1],\n",
    "                            \"yearsOfeducation_2\":YOEdu_list[1],\n",
    "                            \"school_3\":school_list[2],\n",
    "                            \"degree_3\":degree_list[2],\n",
    "                            \"location_3\":location_list[2],\n",
    "                            \"yearsOfeducation_3\":YOEdu_list[2],\n",
    "                            \"school_4\":school_list[3],\n",
    "                            \"degree_4\":degree_list[3],\n",
    "                            \"location_4\":location_list[3],\n",
    "                            \"yearsOfeducation_4\":YOEdu_list[3],\n",
    "                            \"school_5\":school_list[4],\n",
    "                            \"degree_5\":degree_list[4],\n",
    "                            \"location_5\":location_list[4],\n",
    "                            \"yearsOfeducation_5\":YOEdu_list[4]\n",
    "                        },\n",
    "                        \"skills\":skills,\n",
    "                        \"certifications\":certs}) \n",
    "        time.sleep(2)\n",
    "    return True\n",
    "        #break\n",
    "            #Adwards\n",
    "        \n",
    "            #Additional Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on page: 1\n",
      "Yingjie Li\n",
      "Rameshinder Singh Brar\n",
      "Jüri Sildam\n",
      "Sean Wu\n",
      "Yanzhe Li\n",
      "Pooja Khanna\n",
      "Subi Zhang\n",
      "Seyed Hossein Nozadi\n",
      "Vipul Gupta\n",
      "Debolina Das\n",
      "Shashank Reddy\n",
      "Sylvester Chiang\n",
      "Abhinav Sood\n",
      "Sarah Sarabadani\n",
      "Junyu Zhu\n",
      "Farideh Golmakani\n",
      "Barbara Huang\n",
      "Vasyl Lyashkevych\n",
      "Amir Sepasi\n",
      "Wei Zhong\n",
      "Pedram Roshdinavid\n",
      "Santhosh Sharma Ananthramu\n",
      "Fletcher Eugene\n",
      "Hassan Teimoori\n",
      "Pearl Guterman, Phd\n",
      "Xiukun Zhao\n",
      "Nick Tacik\n",
      "Nelson Mendez\n",
      "Dingwen C\n",
      "Orchid Lin\n",
      "Ramesh Sankaranarayanan\n",
      "Rakesh Pawar\n",
      "Suneil Gavaskar Shrivastav\n",
      "Syed Ali\n",
      "Devangkumar Valand\n",
      "Priya Kundu\n",
      "Deepak Kachroo\n",
      "Mark Kos\n",
      "W. Richard Yu\n",
      "Mohammad Peikari\n",
      "Pratiek Matkar\n",
      "Jeff(Jun) Li | Data Science & Data Mining\n",
      "Ronnie Duan\n",
      "Umar Ahsan\n",
      "Julie Narayan\n",
      "Rohit Dev\n",
      "Maliha Haider\n",
      "Alexander Riemer\n",
      "Sander Stepanov\n",
      "Michael Liu\n",
      "working on page: 2\n",
      "Werner Chao\n",
      "Zahra Asiaee\n",
      "Isaac Ahouma\n",
      "Sushmitha M.J\n",
      "Kris Duszak\n",
      "Iris You\n",
      "Davidson Raj\n",
      "Shilpy Sharma\n",
      "Rahul Kothanath\n",
      "Amanjot Kaur\n",
      "Shilpy Sharma\n",
      "Allen Kennedy\n",
      "Michael Levinshtein\n",
      "Jay Gong\n",
      "Andrew Chow\n",
      "Stephen Sherman\n",
      "Elnaz Bigdeli\n",
      "Azadeh Mossannani\n",
      "Shuming Jia\n",
      "Mohit Singh\n",
      "Yifeng He\n",
      "Kyle Imrie\n",
      "Maryam Gholami\n",
      "Ali Moridani\n",
      "Jin Lee\n",
      "Sanaz Golriz\n",
      "Luna Feng\n",
      "Jason Keller\n",
      "Noha Elprince\n",
      "Yifan Tao\n",
      "Fatemeh Vanhari\n",
      "Jaspreet Bassan\n",
      "Keshev Kulkarni\n",
      "Drew Cruickshank\n",
      "Muad Abu-Ata\n",
      "Caiyi Zhu\n",
      "Michael Yan\n",
      "Harshit Talasila\n",
      "Jin Lee\n",
      "Bolong（Danny） Cai\n",
      "Krista Wilson\n",
      "Fahad Shaikh\n",
      "Vlad Skorokhod\n",
      "Amir Ghaderi\n",
      "Biswajit Nandi\n",
      "Stan Slutsky\n",
      "Karolis Jakaitis\n",
      "Victor Comas\n",
      "Kinh-Bang Hoang Duc\n",
      "Maheedhar Kolla\n",
      "working on page: 3\n",
      "Oleg Baydakov\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'location_c' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a18a1fd1979f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'working on page: %d'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mingester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_base\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-244496424fe3>\u001b[0m in \u001b[0;36mingester\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mexperience_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mjobtitle_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mlocation_c_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m#education education-section last\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'location_c' referenced before assignment"
     ]
    }
   ],
   "source": [
    "url_base = 'https://www.indeed.com/resumes?q=data+scientist&l=GTA%2C+ON&co=CA&cb=jt&start='\n",
    "for i in range(0,6):\n",
    "    print('working on page: %d' %(i+1))\n",
    "    ingester(url_base+str(i*50))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch()\n",
    "es.indices.delete(index='resume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "r = requests.get('https://www.indeed.com/resumes?q=data+scientist&l=GTA%2C+ON&co=CA&cb=jt&start=')\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "content = soup.find_all('a', class_= 'app_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:wcd-bd]",
   "language": "python",
   "name": "conda-env-wcd-bd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
